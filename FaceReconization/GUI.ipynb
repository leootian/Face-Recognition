{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-23T19:52:18.365552Z",
     "start_time": "2023-10-23T19:52:18.100194Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mcv2\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtkinter\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mtk\u001B[39;00m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tkinter as tk\n",
    "from tkinter import *\n",
    "from PIL import Image, ImageTk, ImageDraw, ImageFont\n",
    "import tkinter.messagebox\n",
    "import tkinter.simpledialog\n",
    "import tkinter.filedialog\n",
    "import time\n",
    "import os\n",
    "import math\n",
    "from enum import Enum\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "import sv_ttk\n",
    "\n",
    "\n",
    "dataset_path=\"./Dataset/\"\n",
    "lib_path=\"./Libs/\"\n",
    "\n",
    "single_face_filter_factorw=0.12\n",
    "single_face_filter_factorh=0.12\n",
    "vedio_faces_filter_factorw=0.1\n",
    "vedio_faces_filter_factorh=0.1\n",
    "image_faces_filter_factorw=0.1\n",
    "image_faces_filter_factorh=0.1\n",
    "dataset_width=48\n",
    "dataset_height=48\n",
    "\n",
    "sys_state=0\n",
    "sys_state_pre=0\n",
    "time_stamp=0\n",
    "kernel_index=0\n",
    "kernel_list=[]\n",
    "input_count=0\n",
    "input_name=[]\n",
    "FaceMat = []\n",
    "FaceLabel=[]\n",
    "name_list=[]\n",
    "picture_path=[]\n",
    "picture_temp=[]\n",
    "picture_path_temp=[]\n",
    "\n",
    "class sys_state_enum(Enum):\n",
    "  RECOGNIZE_VEDIO=0\n",
    "  RECORD_FACE=1\n",
    "  TRAIN_MODEL=2\n",
    "  LOAD_IMAGE=3\n",
    "  RECOGNIZE_IMAGE=4\n",
    "  RECORD_IMAGE=5\n",
    "  SYS_QUIT=6\n",
    "\n",
    "class recognizer_kernel_enum(Enum):\n",
    "  CASCADE_EIGENFACE=0\n",
    "  FAST_RCNN=1\n",
    "  \n",
    "\n",
    "cap = cv2.VideoCapture(0)#创建摄像头对象\n",
    "face_detecter = cv2.CascadeClassifier(lib_path+\"haarcascade_frontalface_default.xml\")\n",
    "expression_model = torch.load(lib_path+\"model.pkl\", map_location=torch.device('cpu'))\n",
    "expression_model = expression_model.cpu()\n",
    "\n",
    "################################################################表情识别库#################################################################\n",
    "\n",
    "def gaussian_weights_init(m):\n",
    "    \n",
    "    '''\n",
    "    Generate numbers with gaussian distribution\n",
    "    '''\n",
    "    \n",
    "    classname = m.__class__.__name__\n",
    "    # 字符串查找find，找不到返回-1，不等-1即字符串中含有该字符\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.04)\n",
    "\n",
    "class ExpressionCNN(nn.Module):\n",
    "    \n",
    "    '''\n",
    "    Model for expression recognition\n",
    "    '''\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super(ExpressionCNN, self).__init__()\n",
    "        \n",
    "        # layer1(conv + relu + pool)\n",
    "        # input:(batch_size, 1, 48, 48), output(batch_size, 64, 24, 24)\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, 3, 1, 1),\n",
    "            nn.BatchNorm2d(num_features=64),\n",
    "            nn.RReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        # layer2(conv + relu + pool)\n",
    "        # input:(batch_size, 64, 24, 24), output(batch_size, 128, 12, 12)\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, 3, 1, 1),\n",
    "            nn.BatchNorm2d(num_features=128),\n",
    "            nn.RReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        # layer3(conv + relu + pool)\n",
    "        # input: (batch_size, 128, 12, 12), output: (batch_size, 256, 6, 6)\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, 3, 1, 1),\n",
    "            nn.BatchNorm2d(num_features=256),\n",
    "            nn.RReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        # Initialization\n",
    "        self.conv1.apply(gaussian_weights_init)\n",
    "        self.conv2.apply(gaussian_weights_init)\n",
    "        self.conv3.apply(gaussian_weights_init)\n",
    "        \n",
    "        self.fullc = nn.Sequential(\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(256*6*6, 4096),\n",
    "            nn.RReLU(inplace=True),\n",
    "\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(4096, 1024),\n",
    "            nn.RReLU(inplace=True),\n",
    "\n",
    "            nn.Linear(1024, 256),\n",
    "            nn.RReLU(inplace=True),\n",
    "            nn.Linear(256, 7)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        '''\n",
    "        Forward propagation\n",
    "        '''\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = x.view(x.shape[0], -1)  # 数据扁平化\n",
    "        y = self.fullc(x)\n",
    "\n",
    "        return y\n",
    "    \n",
    "expression_dict = {0:\"生气\", 1:\"厌恶\", 2:\"恐慌\", 3:\"高兴\", 4:\"难过\", 5:\"惊讶\", 6:\"中立\"}\n",
    "\n",
    "def expression_recognition(image,exp_model):\n",
    "    model=exp_model\n",
    "    model.eval()\n",
    "    \n",
    "    outputs = model.forward(image)\n",
    "\n",
    "    max_index = torch.argmax(outputs.float())\n",
    "    max_index = max_index.numpy()\n",
    "    max_index = max_index.reshape(1,1)\n",
    "    max_index = max_index[0][0]\n",
    "    # print(\"Result:\", max_index)\n",
    "    # print(\"Expression:\", expression_dict[max_index])\n",
    "    \n",
    "    return expression_dict[max_index]\n",
    "\n",
    "########################################################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "##############################################################GUI功能函数################################################################\n",
    "\n",
    "def face_detection(image):\n",
    "\t# 转成灰度图像\n",
    "  gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "  # 多个尺度空间进行人脸检测   返回检测到的人脸区域坐标信息\n",
    "  faces = face_detecter.detectMultiScale(image=gray, scaleFactor=1.1, minNeighbors=5)\n",
    "  return faces\n",
    "\n",
    "def cv2AddChineseText(img, text, position, textColor=(0, 255, 0), textSize=30):\n",
    "    if (isinstance(img, np.ndarray)):  # 判断是否OpenCV图片类型\n",
    "        img = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    # 创建一个可以在给定图像上绘图的对象\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    # 字体的格式\n",
    "    fontStyle = ImageFont.truetype(\n",
    "        lib_path+\"simsun.ttc\", textSize, encoding=\"utf-8\")\n",
    "    # 绘制文本\n",
    "    draw.text(position, text, textColor, font=fontStyle)\n",
    "    # 转换回OpenCV格式\n",
    "    return cv2.cvtColor(np.asarray(img), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "def display_result(result_text,text_font,text_color,location,pic):\n",
    "  cv2.putText(pic,result_text,location,text_font,1,text_color,2)\n",
    "\n",
    "def splitFrame(ix,iy,ih,iw,frame_input):\n",
    "  if ix>=10:\n",
    "    oxl=ix-10\n",
    "  else:\n",
    "    oxl=ix\n",
    "  if iy>=10:\n",
    "    oyl=iy-10\n",
    "  else:\n",
    "    oyl=iy\n",
    "  if ix+iw+10<frame_input.shape[1]:\n",
    "    oxh=ix+iw+10\n",
    "  else:\n",
    "    oxh=frame_input.shape[1]\n",
    "  oyh=iy+ih\n",
    "  return frame_input[oyl:oyh,oxl:oxh]\n",
    "\n",
    "def recognizeExpression(image):\n",
    "  #image=cv2.resize(image,(48,48))\n",
    "  #image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "  image_hist = cv2.equalizeHist(image)\n",
    "  image_normalized = image_hist.reshape(1, 48, 48) / 255.0\n",
    "  image_tensor = torch.from_numpy(image_normalized)\n",
    "  image_tensor = image_tensor.type('torch.FloatTensor')\n",
    "  image_tensor = image_tensor.unsqueeze(0)\n",
    "\n",
    "  return expression_recognition(image_tensor,expression_model)\n",
    "\n",
    "def recognizeFace(image):\n",
    "  label, confidence = recognizer.predict(image)\n",
    "  return [label, confidence]\n",
    "\n",
    "def recognizeVedio():\n",
    "  global name_list\n",
    "  ref,frame=cap.read()\n",
    "  frame = cv2.flip(frame, 1) #摄像头翻转\n",
    "  frame_temp=frame\n",
    "  vedio_faces_filterw=vedio_faces_filter_factorw*frame.shape[1]\n",
    "  vedio_faces_filterh=vedio_faces_filter_factorh*frame.shape[0]\n",
    "  face_location=face_detection(frame_temp)\n",
    "  if len(face_location)>0:\n",
    "    for x, y, w, h in face_location:\n",
    "      if w>vedio_faces_filterw or h>vedio_faces_filterh:\n",
    "        # 在原图像上绘制矩形标识\n",
    "        cv2.rectangle(img=frame, pt1=(x, y), pt2=(x+w, y+h), color=(0, 0, 255), thickness=2)\n",
    "        face_temp=splitFrame(x, y, w, h,frame_temp)\n",
    "        face_temp = cv2.resize(face_temp,(dataset_width,dataset_height))\n",
    "        face_temp=cv2.cvtColor(face_temp, cv2.COLOR_BGR2GRAY)\n",
    "        str_exp=recognizeExpression(face_temp)\n",
    "        [label,confidence]=recognizeFace(face_temp)\n",
    "        frame=cv2AddChineseText(frame, str(name_list[label-1])+\"/\"+str_exp, (x,y), textColor=(0, 255, 255), textSize=30)\n",
    "  cvimage = cv2.cvtColor(frame, cv2.COLOR_BGR2RGBA)\n",
    "  pilImage=Image.fromarray(cvimage)\n",
    "  pilImage = pilImage.resize((image_width, image_height),Image.ANTIALIAS)\n",
    "  tkImage =  ImageTk.PhotoImage(image=pilImage)\n",
    "  return tkImage\n",
    "\n",
    "def recordFace():\n",
    "  global input_count\n",
    "  global input_name\n",
    "  global dataset_width\n",
    "  global dataset_height\n",
    "  ref,frame=cap.read()\n",
    "  frame = cv2.flip(frame, 1) #摄像头翻转\n",
    "  frame_temp=frame\n",
    "  face_input_filterw=single_face_filter_factorw*frame.shape[1]\n",
    "  face_input_filterh=single_face_filter_factorh*frame.shape[0]\n",
    "  face_location=face_detection(frame_temp)\n",
    "  if len(face_location)==1 and time.time()-time_stamp>input_count:\n",
    "    if face_location[0][2]>face_input_filterw or face_location[0][3]>face_input_filterh:\n",
    "      input_count+=1\n",
    "      for x, y, w, h in face_location:\n",
    "        frame_temp=splitFrame(x, y, w, h,frame_temp)\n",
    "        frame_temp = cv2.resize(frame_temp,(dataset_width,dataset_height))\n",
    "        frame_temp=cv2.cvtColor(frame_temp, cv2.COLOR_BGR2GRAY)\n",
    "      filename=\"s\"+str(input_count).zfill(3)+\".png\"\n",
    "      cv2.imwrite(dataset_path+input_name+\"/\"+filename,frame_temp)\n",
    "  for x, y, w, h in face_location:\n",
    "      # 在原图像上绘制矩形标识\n",
    "      cv2.rectangle(img=frame, pt1=(x, y), pt2=(x+w, y+h), color=(0, 0, 255), thickness=2)\n",
    "  cvimage = cv2.cvtColor(frame, cv2.COLOR_BGR2RGBA)\n",
    "  pilImage=Image.fromarray(cvimage)\n",
    "  pilImage = pilImage.resize((image_width, image_height),Image.ANTIALIAS)\n",
    "  tkImage =  ImageTk.PhotoImage(image=pilImage)\n",
    "  return tkImage\n",
    "\n",
    "def recognizeImage():\n",
    "  global image_faces_filterw\n",
    "  global image_faces_filterh\n",
    "  global name_list\n",
    "  global picture_temp\n",
    "  pic_msg=[]\n",
    "  frame=picture_temp\n",
    "  frame_temp=frame\n",
    "  image_faces_filterw=image_faces_filter_factorw*frame.shape[1]\n",
    "  image_faces_filterh=image_faces_filter_factorw*frame.shape[0]\n",
    "  face_location=face_detection(frame_temp)\n",
    "  if len(face_location)>0:\n",
    "    for x, y, w, h in face_location:\n",
    "      if w>image_faces_filterw or h>image_faces_filterh:\n",
    "        # 在原图像上绘制矩形标识\n",
    "        cv2.rectangle(frame, pt1=(x, y), pt2=(x+w, y+h), color=(0, 0, 255), thickness=2)\n",
    "        face_temp=splitFrame(x, y, w, h,frame_temp)\n",
    "        face_temp = cv2.resize(face_temp,(dataset_width,dataset_height))\n",
    "        face_temp = cv2.cvtColor(face_temp, cv2.COLOR_BGR2GRAY)\n",
    "        str_exp=recognizeExpression(face_temp)\n",
    "        [label,confidence]=recognizeFace(face_temp)\n",
    "        frame=cv2AddChineseText(frame, str(name_list[label-1])+\"/\"+str_exp, (x,y), textColor=(0, 255, 255), textSize=30)\n",
    "  cvimage = cv2.cvtColor(frame, cv2.COLOR_BGR2RGBA)\n",
    "  pilImage=Image.fromarray(cvimage)\n",
    "  if frame.shape[0]/frame.shape[1]>image_height/image_width:\n",
    "    target_width=math.floor(frame.shape[1]*image_height/frame.shape[0])\n",
    "    target_height=image_height\n",
    "  else:\n",
    "    target_width=image_width\n",
    "    target_height=math.floor(frame.shape[0]*image_width/frame.shape[1])\n",
    "  pilImage = pilImage.resize((target_width, target_height),Image.ANTIALIAS)\n",
    "  pic_x=(image_width-target_width)/2\n",
    "  pic_y=(image_height-target_height)/2\n",
    "  tkImage =  ImageTk.PhotoImage(image=pilImage)\n",
    "  pic_msg.append(tkImage)\n",
    "  pic_msg.append(pic_x)\n",
    "  pic_msg.append(pic_y)\n",
    "  return pic_msg\n",
    "\n",
    "def recordImage():\n",
    "  global image_faces_filterw\n",
    "  global image_faces_filterh\n",
    "  global picture_temp\n",
    "  global sys_state\n",
    "  frame=picture_temp\n",
    "  frame_temp=frame\n",
    "  image_faces_filterw=image_faces_filter_factorw*frame.shape[1]\n",
    "  image_faces_filterh=image_faces_filter_factorw*frame.shape[0]\n",
    "  face_location=face_detection(frame_temp)\n",
    "  valid_face_count=0\n",
    "  if len(face_location)>0:\n",
    "    for x, y, w, h in face_location:\n",
    "      if w>image_faces_filterw or h>image_faces_filterh:\n",
    "        valid_face_count+=1\n",
    "        face_temp=splitFrame(x, y, w, h,frame_temp)\n",
    "        face_temp = cv2.resize(face_temp,(dataset_width,dataset_height))\n",
    "        face_temp = cv2.cvtColor(face_temp, cv2.COLOR_BGR2GRAY)\n",
    "    if valid_face_count==1:\n",
    "      correct_name=[]\n",
    "      correct_name = tkinter.simpledialog.askstring(title = '提示',prompt='请输入正确的姓名：')\n",
    "      if not correct_name is None:\n",
    "        if not os.path.exists(dataset_path+correct_name):\n",
    "          os.makedirs(dataset_path+correct_name)\n",
    "        filename_list = os.listdir(dataset_path+correct_name)\n",
    "        index_list=[]\n",
    "        for name in filename_list:\n",
    "          index_list.append(int(name[1:4]))\n",
    "        filename=\"s\"+str(max(index_list)+1).zfill(3)+\".png\"\n",
    "        cv2.imwrite(dataset_path+correct_name+\"/\"+filename,face_temp)\n",
    "        return 1\n",
    "      else:\n",
    "        return 0\n",
    "    else:\n",
    "      tkinter.messagebox.showinfo( \"提示\", \"无效输入，未识别到人脸或识别到多张人脸\")\n",
    "      return 0\n",
    "\n",
    "def recordFacesCallBack():\n",
    "  global sys_state\n",
    "  global time_stamp\n",
    "  global input_count\n",
    "  global input_name\n",
    "  if sys_state!=sys_state_enum.RECORD_FACE:\n",
    "    input_count=0\n",
    "    input_name=[]\n",
    "    input_name = tkinter.simpledialog.askstring(title = '提示',prompt='请输入姓名的汉语拼音：')\n",
    "    if len(input_name)>0:\n",
    "      sys_state=sys_state_enum.RECORD_FACE\n",
    "      if not os.path.exists(dataset_path+input_name):\n",
    "        os.makedirs(dataset_path+input_name)\n",
    "      tkinter.messagebox.showinfo( \"提示\", \"开始录入人脸信息，请正对摄像头并略微转动头部\")\n",
    "      time_stamp=time.time()\n",
    "\n",
    "def is_Chinese(word):\n",
    "  for ch in word:\n",
    "    if '\\u4e00' <= ch <= '\\u9fff':\n",
    "        return True\n",
    "  return False\n",
    "\n",
    "def chooseImageCallBack():\n",
    "  global picture_path\n",
    "  global picture_path_temp\n",
    "  global sys_state\n",
    "  picture_path=[]\n",
    "  picture_path = tkinter.filedialog.askopenfilename()  # 选择目录，返回目录名\n",
    "  if len(picture_path)>0:\n",
    "    if is_Chinese(picture_path):\n",
    "      tkinter.messagebox.showinfo( \"提示\", \"cv2不支持中文路径，请选择英文路径\")\n",
    "    else:\n",
    "      picture_path_temp=picture_path\n",
    "      sys_state=sys_state_enum.LOAD_IMAGE\n",
    "\n",
    "def recognizeVedioCallBack():\n",
    "  global sys_state\n",
    "  sys_state=sys_state_enum.RECOGNIZE_VEDIO\n",
    "\n",
    "def recordImageCallBack():\n",
    "  global sys_state\n",
    "  if sys_state==sys_state_enum.RECOGNIZE_IMAGE:\n",
    "    tkinter.messagebox.showinfo( \"警告\", \"此操作会扩充训练集\")\n",
    "    sys_state=sys_state_enum.RECORD_IMAGE\n",
    "  else:\n",
    "    tkinter.messagebox.showinfo( \"提示\", \"仅支持图片的勘误\")\n",
    "\n",
    "def kernelChooseCallBack(*args):\n",
    "  global kernel_index\n",
    "  kernel_index=kernel_list.index(kernel_mode.get())\n",
    "\n",
    "def _quit():\n",
    "  global sys_state\n",
    "  sys_state=sys_state_enum.SYS_QUIT\n",
    "\n",
    "########################################################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "###############################################################界面初始化################################################################\n",
    "\n",
    "top = tk.Tk()\n",
    "#sv_ttk.set_theme(\"dark\")\n",
    "top.protocol(\"WM_DELETE_WINDOW\", _quit)\n",
    "top.title('模式识别课程作业-人脸识别demo')\n",
    "top.geometry('1600x800')\n",
    "image_width = 800\n",
    "image_height = 600\n",
    "canvas_input = Canvas(top,bg = 'black',width = image_width,height = image_height )#绘制输入\n",
    "Label(top,text = '图像输入',font = (\"黑体\",14),width =15,height = 1).place(x =700,y = 20,anchor = 'nw')\n",
    "canvas_input.place(x = 380,y = 50)\n",
    "\n",
    "\n",
    "Button1 = Button(top, text =\"录入人脸\", command = recordFacesCallBack,relief=RAISED,height=2,width=20)\n",
    "Button1.place(x=250, y=680)\n",
    "Button2 = Button(top, text =\"载入图片\", command = chooseImageCallBack,relief=RAISED,height=2,width=20)\n",
    "Button2.place(x=550, y=680)\n",
    "Button2 = Button(top, text =\"摄像头实时识别\", command = recognizeVedioCallBack,relief=RAISED,height=2,width=20)\n",
    "Button2.place(x=850, y=680)\n",
    "Button3 = Button(top, text =\"手动勘误\", command = recordImageCallBack,relief=RAISED,height=2,width=20)\n",
    "Button3.place(x=1150, y=680)\n",
    "for item in recognizer_kernel_enum:\n",
    "  kernel_list.append(item.name)\n",
    "kernel_mode=tkinter.StringVar(top)\n",
    "kernel_mode.set(kernel_list[0])\n",
    "OptionMenu1 = OptionMenu(top, kernel_mode, *kernel_list)\n",
    "OptionMenu1.place(x=100, y=50)\n",
    "kernel_mode.trace(\"w\", kernelChooseCallBack)\n",
    "Label(top,text = '选择内核',font = (\"黑体\",10),height = 1).place(x=30, y=58)\n",
    "\n",
    "########################################################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "#################################################################主循环##################################################################\n",
    "\n",
    "sys_state=sys_state_enum.TRAIN_MODEL\n",
    "\n",
    "while True:\n",
    "  if sys_state==sys_state_enum.RECOGNIZE_VEDIO:\n",
    "    pic = recognizeVedio()\n",
    "    canvas_input.create_image(0,0,anchor = 'nw',image = pic)\n",
    "\n",
    "  elif sys_state==sys_state_enum.RECORD_FACE:\n",
    "    pic = recordFace()\n",
    "    canvas_input.create_image(0,0,anchor = 'nw',image = pic)\n",
    "    if time.time()>time_stamp+8:\n",
    "      sys_state_pre=sys_state_enum.RECORD_FACE\n",
    "      sys_state=sys_state_enum.TRAIN_MODEL\n",
    "      tkinter.messagebox.showinfo( \"提示\", \"录入成功！\")\n",
    "      input_name=[]\n",
    "\n",
    "  elif sys_state==sys_state_enum.TRAIN_MODEL:\n",
    "    train_msg=Label(top,text = '模型训练中。。。',font = (\"黑体\",10),width =15,height = 1)\n",
    "    train_msg.place(x =700,y = 800,anchor = 'nw')\n",
    "    name_list = os.listdir(dataset_path)\n",
    "    i=0\n",
    "    if len(name_list)>0:\n",
    "      FaceMat=[]\n",
    "      FaceLabel=[]\n",
    "      for name in name_list:\n",
    "        i+=1\n",
    "        for dir_item in os.listdir(dataset_path+name):\n",
    "          FaceMat.append(cv2.imread(dataset_path+name+\"/\"+dir_item, cv2.IMREAD_GRAYSCALE))\n",
    "          FaceLabel.append(i)\n",
    "      recognizer = cv2.face.EigenFaceRecognizer_create()\n",
    "      recognizer.train(FaceMat, np.array(FaceLabel))\n",
    "      train_msg.destroy()\n",
    "      if sys_state_pre==sys_state_enum.RECORD_IMAGE:\n",
    "        sys_state=sys_state_enum.RECOGNIZE_IMAGE\n",
    "      else:\n",
    "        sys_state=sys_state_enum.RECOGNIZE_VEDIO\n",
    "    else:\n",
    "      tkinter.messagebox.showinfo( \"提示\", \"缺少训练集，无法训练模型，请录入人脸！\")\n",
    "      recordFacesCallBack()\n",
    "\n",
    "  elif sys_state==sys_state_enum.LOAD_IMAGE:\n",
    "    picture_temp=cv2.imread(picture_path,cv2.IMREAD_UNCHANGED)\n",
    "    sys_state=sys_state_enum.RECOGNIZE_IMAGE\n",
    "\n",
    "  elif sys_state==sys_state_enum.RECOGNIZE_IMAGE:\n",
    "    if len(picture_path)>0:\n",
    "      pic = recognizeImage()\n",
    "      canvas_input.create_image(pic[1],pic[2],anchor = 'nw',image = pic[0])\n",
    "      picture_path=[]\n",
    "\n",
    "  elif sys_state==sys_state_enum.RECORD_IMAGE:\n",
    "    picture_temp=cv2.imread(picture_path_temp,cv2.IMREAD_UNCHANGED)\n",
    "    if recordImage():\n",
    "      picture_path=picture_path_temp\n",
    "      sys_state_pre=sys_state_enum.RECORD_IMAGE\n",
    "      sys_state=sys_state_enum.TRAIN_MODEL\n",
    "    else:\n",
    "      sys_state=sys_state_enum.RECOGNIZE_IMAGE\n",
    "\n",
    "  else:\n",
    "    top.quit()\n",
    "    cap.release()\n",
    "    top.destroy()\n",
    "    break\n",
    "\n",
    "  top.update()\n",
    "  top.after(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ae3de2051564696ccd7470376302ad682b949adc658f5250b0253e63976b9ba8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
